{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader.MedSegReader import MedSegSimpleReader\n",
    "from train_tools.EarlyStopper import EarlyStopper\n",
    "from train_tools.BestSaver import BestSaver\n",
    "from reader.ctimageio import *\n",
    "from metrics.multilabel import *\n",
    "from net.Unet2D import Unet2D\n",
    "\n",
    "from module.display import *\n",
    "import torch\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"MedSeg/Liver/\"\n",
    "ms_reader = MedSegSimpleReader(path, isFlip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeCTMask(source_mask, resize_shape):\n",
    "    labels = [i+1 for i in range(9)]\n",
    "\n",
    "    segments = [np.array(np.where(source_mask==label, 1, 0), dtype=np.uint8) for label in labels] # 分別取得各segment的mask\n",
    "    segments = [cv2.resize(segment, resize_shape, interpolation=cv2.INTER_LINEAR) \n",
    "                        for segment in segments]\n",
    "    \n",
    "    check_mask = np.zeros(resize_shape) # 紀錄resize後，label的重疊情形\n",
    "    resized_mask = np.zeros(resize_shape)\n",
    "    for label, segment in zip(labels, segments):\n",
    "        check_mask += segment\n",
    "        resized_mask += segment*label\n",
    "\n",
    "    if len(np.unique(check_mask)) > 2: # label有重疊到 (以確認過只會重疊一次 overlap_mask==2的部分)\n",
    "        overlap_ys, overlap_xs = np.where(check_mask==2)\n",
    "        resized_mask[overlap_ys, overlap_xs] = 0 # 把重疊的部分改為0\n",
    "\n",
    "        # overlap_mask[overlap_ys, overlap_xs] = 0 # 檢查用\n",
    "        # print(np.unique(overlap_mask))\n",
    "    return resized_mask\n",
    "\n",
    "class MSDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, reader, pt_indices, resize_shape=(256, 256), targetonly=False):\n",
    "        self.imgs = []\n",
    "        self.masks = []\n",
    "\n",
    "        for index in pt_indices:\n",
    "            ct_slices, ct_masks = reader[index] # patient images\n",
    "            if resize_shape != None:\n",
    "                ct_slices, ct_masks = self.__resize(ct_slices, ct_masks, resize_shape)\n",
    "                \n",
    "            for ct_slice, ct_mask in zip(ct_slices, ct_masks):                \n",
    "                if targetonly: # 只保留有Target Segments的部分\n",
    "                    if np.sum(ct_mask) == 0:\n",
    "                        continue\n",
    "\n",
    "                self.imgs.append(ct_slice)\n",
    "                self.masks.append(ct_mask)\n",
    "        self.imgs = np.array(self.imgs)\n",
    "        self.masks = np.array(self.masks)\n",
    "\n",
    "    def __resize(self, ct_slices, ct_masks, resize_shape):\n",
    "        resized_slices, resized_masks = [], []\n",
    "        for ct_slice, ct_mask in zip(ct_slices, ct_masks):                \n",
    "            ct_slice = cv2.resize(ct_slice, resize_shape, interpolation=cv2.INTER_LINEAR)\n",
    "            ct_mask = resizeCTMask(ct_mask, resize_shape)\n",
    "            ct_slice = np.clip(ct_slice, -160, 240)\n",
    "\n",
    "            resized_slices.append(ct_slice)\n",
    "            resized_masks.append(ct_mask)\n",
    "        return np.array(resized_slices), np.array(resized_masks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.imgs[idx]\n",
    "        mask = self.masks[idx]\n",
    "\n",
    "        img = torch.from_numpy(img)\n",
    "        img = torch.unsqueeze(img, 0).type(torch.float32)\n",
    "        mask = torch.from_numpy(mask).type(torch.int64)\n",
    "        mask = torch.nn.functional.one_hot(mask, num_classes=10).permute(2, 0, 1).float()\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    raise PermissionError(\"Not detect GPU devices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "criterion = multilabel_dice_loss\n",
    "\n",
    "def evaluate(model, data_loader, o_dataset, device):\n",
    "    model.eval()\n",
    "    targets = [mask for _, mask in o_dataset]\n",
    "    targets = torch.stack(targets)\n",
    "\n",
    "    # Get model outputs\n",
    "    outputs = []\n",
    "    for images, _ in data_loader:\n",
    "        X = images.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outs = model(X)\n",
    "\n",
    "        outs = outs.cpu()\n",
    "        outputs.append(outs)\n",
    "    outputs = torch.vstack(outputs)\n",
    "    outputs = outputs.permute(0,2,3,1)\n",
    "    outputs = np.argmax(outputs.numpy(), axis=-1)\n",
    "\n",
    "    # Output resize\n",
    "    prediction = []\n",
    "    for mask in outputs:\n",
    "        resized_mask = resizeCTMask(mask, (512, 512))\n",
    "        resized_mask = torch.from_numpy(resized_mask).type(torch.int64)\n",
    "        resized_mask = torch.nn.functional.one_hot(resized_mask, num_classes=10).permute(2, 0, 1).float()\n",
    "        prediction.append(resized_mask)\n",
    "    prediction = torch.stack(prediction)\n",
    "\n",
    "    dice_global = multilabel_dice(prediction, targets) # Calculation of dice global\n",
    "    no_bg_dice = dice_coeff_no_bg(prediction, targets)\n",
    "    label_dice = dice_all_labels(prediction, targets)\n",
    "\n",
    "    return dice_global.item(), no_bg_dice.item(), label_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import openpyxl\n",
    "\n",
    "result_filename = \"2DResult.xlsx\"\n",
    "\n",
    "# 檢查檔案是否存在\n",
    "if Path(result_filename).is_file():\n",
    "    # 如果存在，刪除該檔案\n",
    "    os.remove(result_filename)\n",
    "\n",
    "# 建立一個新的Excel檔案\n",
    "workbook = openpyxl.Workbook()\n",
    "workbook.save(result_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Test dice global: 0.7506187558174133\n",
      "No Background dice: 0.7546030282974243\n",
      "Each label dice: [0.9976194500923157, 0.3883272111415863, 0.7677257657051086, 0.8020117878913879, 0.6446415781974792, 0.7794450521469116, 0.7919529676437378, 0.7889350056648254, 0.7706326842308044, 0.774895429611206]\n",
      "\n",
      "Fold 2\n",
      "Test dice global: 0.751479983329773\n",
      "No Background dice: 0.7265217900276184\n",
      "Each label dice: [0.9971669316291809, 0.7165870666503906, 0.8325670957565308, 0.7559942603111267, 0.6395816206932068, 0.6679778099060059, 0.7434919476509094, 0.7181137800216675, 0.7400827407836914, 0.7032361626625061]\n",
      "\n",
      "Fold 3\n",
      "Test dice global: 0.7467681765556335\n",
      "No Background dice: 0.7101786136627197\n",
      "Each label dice: [0.997839093208313, 0.6633767485618591, 0.8101839423179626, 0.8221350908279419, 0.6798381805419922, 0.7739604711532593, 0.7231922745704651, 0.7156186699867249, 0.6066797971725464, 0.6748578548431396]\n",
      "\n",
      "Fold 4\n",
      "Test dice global: 0.7192608714103699\n",
      "No Background dice: 0.7095493078231812\n",
      "Each label dice: [0.9952560067176819, 0.6942792534828186, 0.731768012046814, 0.49002403020858765, 0.6595118641853333, 0.633359432220459, 0.7586315870285034, 0.7337936758995056, 0.7307473421096802, 0.76523756980896]\n",
      "\n",
      "Fold 5\n",
      "Test dice global: 0.753384530544281\n",
      "No Background dice: 0.7533434629440308\n",
      "Each label dice: [0.9950916767120361, 0.7646726369857788, 0.46406397223472595, 0.7769188284873962, 0.6131560802459717, 0.6968337893486023, 0.7786442041397095, 0.8070652484893799, 0.8635284900665283, 0.7738708853721619]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_indices = [i for i in range(len(ms_reader))]\n",
    "kf = KFold(n_splits=5)\n",
    "# 創建一個空的DataFrame\n",
    "df = pd.DataFrame(columns=[\"fold_num\", \"bg\", \"S1\", \"S2\", \"S3\", \"S4a\", \"S4b\", \"S5\", \"S6\", \"S7\", \"S8\", \"dice_global\", \"No_bg\"])\n",
    "df.to_excel(result_filename, index=False)\n",
    "\n",
    "for fold_num, (train_indices, test_indices) in enumerate(kf.split(sample_indices)):\n",
    "    print(f\"Fold {fold_num+1}\")\n",
    "    model_save_name = f\"save_model/Unet2D/Unet2D_fold{fold_num+1}.pth\"\n",
    "            \n",
    "    model = Unet2D(n_classes=10).to(device)\n",
    "\n",
    "    #################\n",
    "    #  Test Dataset #\n",
    "    #################\n",
    "    dataset_test = MSDataset(ms_reader, test_indices)\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=batch_size, shuffle=False)\n",
    "    o_dataset_test = MSDataset(ms_reader, test_indices, None)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_save_name))\n",
    "    dice_global, no_bg_dice, label_dice = evaluate(model, data_loader_test, o_dataset_test, device)\n",
    "    print(f\"Test dice global: {dice_global}\")\n",
    "    print(f\"No Background dice: {no_bg_dice}\")\n",
    "    print(f\"Each label dice: {label_dice}\")\n",
    "    print()\n",
    "    df = pd.read_excel(result_filename)\n",
    "    fold_result = [fold_num+1] + label_dice + [dice_global, no_bg_dice]\n",
    "    df.loc[-1] = fold_result\n",
    "    df.index = df.index + 1\n",
    "    df.to_excel(result_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
